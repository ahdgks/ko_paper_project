{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d9bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "import os\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "from transformers import AdamW, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit, PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments,BitsAndBytesConfig\n",
    "num=1\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "#이 체인은 메모리를 가지고 있는 체인이다\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# 기본 라이브러리 임포트\n",
    "\n",
    "# PyTorch 관련\n",
    "\n",
    "from torch import torch\n",
    "from torch import cuda, bfloat16\n",
    "\n",
    "# Transformers 관련\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    GenerationConfig,\n",
    "    pipeline,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "import os\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "from transformers import AdamW, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit, PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments,BitsAndBytesConfig\n",
    "num=1\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "#이 체인은 메모리를 가지고 있는 체인이다\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# 기본 라이브러리 임포트\n",
    "\n",
    "# PyTorch 관련\n",
    "\n",
    "from torch import torch\n",
    "from torch import cuda, bfloat16\n",
    "\n",
    "# Transformers 관련\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    GenerationConfig,\n",
    "    pipeline,\n",
    ")\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments,BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "\n",
    "# LangChain 관련\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "# LangChain Community 관련\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#메모리를 가진 체인을 구현하기 위해서는 ConversationBufferMemory를 통해 몇개까지 기억할 것인가를 정함\n",
    "from langchain.vectorstores import FAISS\n",
    "from torch import cuda, bfloat16\n",
    "# from streamlit_chat import message\n",
    "#아래는 둘다 메모리 기억을 위한 라이브러리\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import StreamlitChatMessageHistory\n",
    "# LangChain 관련\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "# LangChain Community 관련\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#메모리를 가진 체인을 구현하기 위해서는 ConversationBufferMemory를 통해 몇개까지 기억할 것인가를 정함\n",
    "from langchain.vectorstores import FAISS\n",
    "from torch import cuda, bfloat16\n",
    "# from streamlit_chat import message\n",
    "#아래는 둘다 메모리 기억을 위한 라이브러리\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import StreamlitChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376fcc5",
   "metadata": {},
   "source": [
    "# fine_tuning 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8ae8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166ef76238b34033bb0ed4f10977dcc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#qlora모델 로드하는 코드\n",
    "adapter_dir = f'./results{num}/final_checkpoint'\n",
    "output_dir = f'./merged_peft{num}'\n",
    "output_merged_dir = os.path.join(output_dir, \"final_merged_checkpoint\")\n",
    "\n",
    "DEV = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "model_name =output_merged_dir\n",
    "adapter_path = f'./results{num}/final_checkpoint'\n",
    "# adapter_path = \"./dpo_results/final_checkpoint\"\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    adapter_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_merged_dir)\n",
    "tokenizer.eos_token='</s>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6013d5",
   "metadata": {},
   "source": [
    "# vector_db 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fabac551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어에 임베딩할 모델 선언\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "model_name = 'intfloat/multilingual-e5-large'\n",
    "model_kwargs = {\"device\":\"cuda\"}\n",
    "encode_kwargs={'normalize_embeddings':True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f164ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장된 벡터 db에서 불러오기\n",
    "vector_db = Chroma(persist_directory=\"./version_10\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63b4bd",
   "metadata": {},
   "source": [
    "# Pipeline 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde3ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "#허깅페이스 pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import LlamaForCausalLM, AutoTokenizer, pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, max_new_tokens=512,tokenizer=tokenizer, device_map=\"auto\")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e5f3a",
   "metadata": {},
   "source": [
    "# 랭체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e42cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랭체인 구성\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_db.as_retriever(search_type = 'mmr',search_kwargs={'k':3,'fetch_k':3}, vervose = True),\n",
    "        memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),\n",
    "        get_chat_history=lambda h: h,\n",
    "        return_source_documents=True,\n",
    "        verbose = True\n",
    "    )\n",
    "conversation_chain.combine_docs_chain.llm_chain.prompt.template = \"\"\"너는 논문 검색 도우미야. 맥락을 참고해서 답해줘. 답변의 시작은 \"관련된 논문으로 ~~가 있습니다\" 로 해줘.if you can't answer, please say 잘 모르겠습니다.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    질문: {question}\n",
    "\n",
    "    논문 검색 결과:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b89dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t16user1/.conda/envs/ahdgks/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m너는 논문 검색 도우미야. 맥락을 참고해서 답해줘. 답변의 시작은 \"관련된 논문으로 ~~가 있습니다\" 로 해줘.if you can't answer, please say 잘 모르겠습니다.\n",
      "\n",
      "    이 논문의 제목은 \"경제학의 기본개념을 통한 경제교육 방안\"이다. 저자는 \"김진영\"이다. 발행연도는 \"2007\"이다.논문의 내용은 경제 소양 혹은 경제 이해력은 개인과 국가 경쟁력을 결정하는 요인으로 경제교육의 필요성에 대해 이의를 제기하는 사람은 없다. 그러나 경제교육에서 어떻게, 무엇을 가르쳐야 하는 것인지는 밝혀져야 할 내용이 더 많다.  이다.\n",
      "\n",
      "이 논문의 제목은 \"경제학의 기본개념을 통한 경제교육 방안\"이다. 저자는 \"김진영\"이다. 발행연도는 \"2007\"이다.논문의 내용은 경제 소양 혹은 경제 이해력은 개인과 국가 경쟁력을 결정하는 요인으로 경제교육의 필요성에 대해 이의를 제기하는 사람은 없다. 그러나 경제교육에서 어떻게, 무엇을 가르쳐야 하는 것인지는 밝혀져야 할 내용이 더 많다.  이다.\n",
      "\n",
      "이 논문의 제목은 \"에 나타난 유학사상의 경제관 연구\"이다. 저자는 \"김조영\"이다. 발행연도는 \"2016\"이다.논문의 내용은 본 논문은 경제적 가치를 최고로 여기는 근대 자본주의 경제관의 단점을 극복하기 위해, 인간다움의 정체성을 추구하는 유학의 경제관을 를 통해 분석하여 자본주의 경제관과 비교한 뒤 그 시사점을 밝히고 추구하고자 한다.  이다.\n",
      "\n",
      "    질문: 경제학에 대한 논문을 찾아줘\n",
      "\n",
      "    논문 검색 결과:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n    1. 경제학의  기본개념 을 통한 경제교육  방안 \\n    저자: 김진영\\n    발행연도: 2007\\n\\n    2. 에 나타난 유학사상 의 경제 관 연구 \\n    저자: 김조영\\n    발행연도: 2016'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숫자 바꾸면 대화 바뀜\n",
    "answer=conversation_chain('경제학에 대한 논문을 찾아줘')\n",
    "answer['chat_history'][1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4debc6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '경제학에 대한 논문을 찾아줘',\n",
       " 'chat_history': [HumanMessage(content='경제학에 대한 논문을 찾아줘'),\n",
       "  AIMessage(content='\\n\\n    1. 경제학의  기본개념 을 통한 경제교육  방안 \\n    저자: 김진영\\n    발행연도: 2007\\n\\n    2. 에 나타난 유학사상 의 경제 관 연구 \\n    저자: 김조영\\n    발행연도: 2016')],\n",
       " 'answer': '\\n\\n    1. 경제학의  기본개념 을 통한 경제교육  방안 \\n    저자: 김진영\\n    발행연도: 2007\\n\\n    2. 에 나타난 유학사상 의 경제 관 연구 \\n    저자: 김조영\\n    발행연도: 2016',\n",
       " 'source_documents': [Document(page_content='이 논문의 제목은 \"경제학의 기본개념을 통한 경제교육 방안\"이다. 저자는 \"김진영\"이다. 발행연도는 \"2007\"이다.논문의 내용은 경제 소양 혹은 경제 이해력은 개인과 국가 경쟁력을 결정하는 요인으로 경제교육의 필요성에 대해 이의를 제기하는 사람은 없다. 그러나 경제교육에서 어떻게, 무엇을 가르쳐야 하는 것인지는 밝혀져야 할 내용이 더 많다.  이다.', metadata={'date': 2007, 'doc_id': 'A201008117477', 'ipc': '사회과학', 'title': '경제학의 기본개념을 통한 경제교육 방안'}),\n",
       "  Document(page_content='이 논문의 제목은 \"경제학의 기본개념을 통한 경제교육 방안\"이다. 저자는 \"김진영\"이다. 발행연도는 \"2007\"이다.논문의 내용은 경제 소양 혹은 경제 이해력은 개인과 국가 경쟁력을 결정하는 요인으로 경제교육의 필요성에 대해 이의를 제기하는 사람은 없다. 그러나 경제교육에서 어떻게, 무엇을 가르쳐야 하는 것인지는 밝혀져야 할 내용이 더 많다.  이다.', metadata={'date': 2007, 'doc_id': 'A201008117477', 'ipc': '사회과학', 'title': '경제학의 기본개념을 통한 경제교육 방안'}),\n",
       "  Document(page_content='이 논문의 제목은 \"에 나타난 유학사상의 경제관 연구\"이다. 저자는 \"김조영\"이다. 발행연도는 \"2016\"이다.논문의 내용은 본 논문은 경제적 가치를 최고로 여기는 근대 자본주의 경제관의 단점을 극복하기 위해, 인간다움의 정체성을 추구하는 유학의 경제관을 를 통해 분석하여 자본주의 경제관과 비교한 뒤 그 시사점을 밝히고 추구하고자 한다.  이다.', metadata={'date': 2016, 'doc_id': 'A201008125521', 'ipc': '인문학', 'title': '에 나타난 유학사상의 경제관 연구'})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ee65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahdgks",
   "language": "python",
   "name": "ahdgks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
