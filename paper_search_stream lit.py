{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9c2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253315b",
   "metadata": {},
   "source": [
    "streamlit에서 사이드바(위키독스 같은) 구현하는 방법\n",
    "\n",
    "st.sidebar하면 됨\n",
    "\n",
    "그만큼 쉬움\n",
    "\n",
    "유의점: 우리가 구현해야할 체인은 우리가 질문한것에 답변할 뿐만아니라 이전에 대답한것을 기억해서 메모리를 가진 체인을 구성하는 것이다\n",
    "\n",
    "ex)한글 텍스트 분석의 어려움이 뭐야 라고 질문하고 다음 질문으로 요약해줘 라고 했을 이때 한글 텍스트 분석의 어려움을 요약하게 하는게 핵심이다\n",
    "\n",
    "이럴 때는 다른 체인을 써야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06037bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tiktoken#tiktoken은 토큰 갯수를 세기위한 라이브러리\n",
    "from loguru import logger # 행동을 취했을 때 streamlit사이트상에서 log로 남기는것\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "#이 체인은 메모리를 가지고 있는 체인이다\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "#poc?에서 원한게 여러 유형의 문서를 넣어도 이해가 되는걸 원했음 그래서 이걸로함\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#메모리를 가진 체인을 구현하기 위해서는 ConversationBufferMemory를 통해 몇개까지 기억할 것인가를 정함\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# from streamlit_chat import message\n",
    "#아래는 둘다 메모리 기억을 위한 라이브러리\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import StreamlitChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6145db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:394\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:439\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/safe_session_state.py:89\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:396\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 174\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# 함수실행하면 시작됨\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m#만약 이 파일이 실행되면 poc로 만들 화면의 스크립트가 모두작성되는것임\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     44\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m안녕하세요! 한국 논문 검색 전용 챗봇입니다! 찾고 싶은 논문이 있으면 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~~에 대한 논문을 찾아줘\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 라고 요청해 보세요! \u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 메세지마다 with 구문으로 묶어주고 role에 따라 markdown한다는 코드\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 어떤 아이콘 안에다가 어떤 content에 따른 텍스트를 적어라\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#for문으로 구성해서 메세지가 올라올때마다 이 모든걸 수행함\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m st\u001b[38;5;241m.\u001b[39mchat_message(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     50\u001b[0m             st\u001b[38;5;241m.\u001b[39mmarkdown(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/ahdgks/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#메인함수와 메인함수를 구현하기 위한 유틸리티 함수들\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "    page_title=\"논문검색 챗봇\",\n",
    "    page_icon=\":books:\")\n",
    "#st.set_page_config 페이지의 상세상황에 대해 정리함\n",
    "#page_title 탭에서 보임, 탭 icon\n",
    "    st.title(\"_한국 논문 검색 :red[챗봇]_ :books:\")\n",
    "#페이지에 보이는 제목 정하기 _를 하면 기울임꼴, red-색상,books-아이콘\n",
    "    if \"conversation\" not in st.session_state:\n",
    "        st.session_state.conversation = None\n",
    "#st.session_state에 conversation이 없으면 None으로 설정해라\n",
    "#이후에 st.session_state.conversation변수를 쓰기위해 설정함\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = None\n",
    "\n",
    "    if \"processComplete\" not in st.session_state:\n",
    "        st.session_state.processComplete = None\n",
    "#with문 의 경우 어떤 구성요소안에 그 하위 구성요소들이 집행되어야 하는 경우쓰임\n",
    "#예를 들어 사이드바는 사이드바 안에 뭘 넣기 위해 쓰는거니 with를 쓴다.\n",
    "# 이 구문 아래 file_uploader기능을 넣고  process도 이 코드 하나로 구현가능\n",
    "    with st.sidebar:\n",
    "        uploaded_files =  st.file_uploader(\"Upload your file\",type=['pdf','docx'],accept_multiple_files=True)\n",
    "        openai_api_key = st.text_input(\"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n",
    "        process = st.button(\"Process\")\n",
    "    if process:\n",
    "   # 이 버튼을 누르면 구동되는 부분 정의한 것      \n",
    "        if not openai_api_key:\n",
    "            st.info(\"Please add your OpenAI API key to continue.\")\n",
    "            st.stop()#안되면 이 과정이 멈추게함\n",
    "        files_text = get_text(uploaded_files)\n",
    "        #입력이 되었다면 get_text를 통해 텍스트로 변환함\n",
    "        text_chunks = get_text_chunks(files_text)\n",
    "        #텍스트로  get_text_chunks청크로 나눔\n",
    "        vetorestore = get_vectorstore(text_chunks)\n",
    "     #벡터스토어에 저장함\n",
    "        st.session_state.conversation = get_conversation_chain(vetorestore,openai_api_key) \n",
    "#벡터스토어를 갖고 체인을 구성하는 코드 해당 변수는 st.session_state.conversation\n",
    "        st.session_state.processComplete = True\n",
    "#message는 채팅화면을 구현하기 위한 코드\n",
    "#세션상태를 유지해서 전에 한 대화도 유지시키기 위한 코드\n",
    "    if 'messages' not in st.session_state:\n",
    "        st.session_state.messages = [{\"role\": \"assistant\", \n",
    "                                        \"content\": \"안녕하세요! 한국 논문 검색 전용 챗봇입니다! 찾고 싶은 논문이 있으면 '~~에 대한 논문을 찾아줘' 라고 요청해 보세요! \"}]\n",
    "# 메세지마다 with 구문으로 묶어주고 role에 따라 markdown한다는 코드\n",
    "# 어떤 아이콘 안에다가 어떤 content에 따른 텍스트를 적어라\n",
    "#for문으로 구성해서 메세지가 올라올때마다 이 모든걸 수행함\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "#history를 정의해줘야 LLM이 메모리를 갖고 컨텍스트를 고려해서 답변하기 때문에 이걸 구현해줘야함\n",
    "    history = StreamlitChatMessageHistory(key=\"chat_messages\")\n",
    "\n",
    "    # Chat logic\n",
    "    #chat_input은 질문창임 if문은 사용자가 질문을 입력하면임\n",
    "    if query := st.chat_input(\"질문을 입력해주세요.\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
    "#입력이 되면 session_state에만 입력될게 아니라 화면에도 띄어져야 되므로 with를 통해 작성됨\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(query)\n",
    "\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            chain = st.session_state.conversation\n",
    "#로딩할때 똥글똥글하게 돌아가는 부분을 표시해주는게 spinner다. 표시하기 위해 with로함\n",
    "            with st.spinner(\"관련 논문을 찾는 중입니다...\"):\n",
    "#답변이 나오기 전까지 구동이 되어야하므로 로딩 구문 밑에 chain실행함\n",
    "#이 체인은 위에서 설정한 것처럼 session.state의 conversation이다\n",
    "#session.state의 conversation은 get_conversation 함수를 실행한 것과 같다\n",
    "#그래서 session.state의 conversation을 chain으로 가져오고 chain에 쿼리를 넣어주면 llm의 답변이 나옴\n",
    "                result = chain({\"question\": query})\n",
    "\n",
    "#open ai callback을 통해 우리가 받은 chat history를 저장한다\n",
    "                with get_openai_callback() as cb:\n",
    "                    st.session_state.chat_history = result['chat_history']\n",
    "# 받은 결과를 response로 담고 참고한 문서를 source_documents로 담음\n",
    "                response = result['answer']\n",
    "                source_documents = result['source_documents']\n",
    "#정상적으로 assistance 아이콘 다음에 나오는 컨텐츠를 response로 적는다\n",
    "                st.markdown(response)\n",
    "#expander는 vscode에도 접었다가 폈다가 하는 부분이 있는데 이걸 expander로 한다\n",
    "#어떤 답변에 대한 참고 문서를 내가 원할때마다 접었다 폈다해줌\n",
    "#이것 만으로 접은 영역에 어떻게 컨텐츠를 접을지를 명시함\n",
    "#help를 적으면 물음표 모양의 아이콘이 뜸 거기에 마우스 후버?를 하면 로드중이나 원하는 텍스트 뜨게할 수 ㅣㅇㅆ음\n",
    "#이번에는 참고한 문서의 어떤 chunk를 참고했는지 띄울 수 있음\n",
    "                with st.expander(\"참고 문서 확인\"):\n",
    "                    st.markdown(source_documents[0].metadata['source'], help = source_documents[0].page_content)\n",
    "                    st.markdown(source_documents[1].metadata['source'], help = source_documents[1].page_content)\n",
    "                    st.markdown(source_documents[2].metadata['source'], help = source_documents[2].page_content)\n",
    "                    \n",
    "\n",
    "\n",
    "# Add assistant message to chat history\n",
    "#세션 스테이트에 어시서턴트가 답변한것도 함께 기록함\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "#유틸리티 함수들임 토큰 갯수를 기준으로 spliting해주기 위한 함수\n",
    "def tiktoken_len(text):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "#업로드된 파일을 텍스트로 변환하는 과정을 담은 함수\n",
    "\n",
    "def get_text(docs):\n",
    "#여러개의 파일을 처리해서 doc_list로 선언함\n",
    "    doc_list = []\n",
    "    #각 파일 종류에 대해 해야할 일을 적음\n",
    "    for doc in docs:\n",
    "        file_name = doc.name  # doc 객체의 이름을 파일 이름으로 사용\n",
    "        with open(file_name, \"wb\") as file:  # 파일을 doc.name으로 저장\n",
    "            file.write(doc.getvalue())\n",
    "            #파일 업로드한걸 로그로 남김\n",
    "            #원래는 로더안에 로컬경로를 넣으면 되는데 streamlit은 배포를 했을 때 로컬에서만 작동되는게 \n",
    "#아니라 클라우드 상에서 작동이 되어 사람들이 자기의 파일을 넣었을 때 채팅이 되게 만드는 것이다 이 경우 우리의저장결로를 주는게 아니라 스트림 릿 클라우드 pc상에 돌아가는 파일의 임시 저장경로를 제공해야한다 그게 filename임\n",
    "#with open을 하면 파일이 열린다. 근데 우리는 file을 저장한적이없다 위에서는 이름만 부여함 따라서 빈파일이 생김\n",
    "#우리는 getvalue로 해당 파일에 맞는 진짜 파일을 넣어줌 그럼 doc에 대한 내용을 file에 저장가능\n",
    "\n",
    "            logger.info(f\"Uploaded {file_name}\")\n",
    "        if '.pdf' in doc.name:\n",
    "            loader = PyPDFLoader(file_name)\n",
    "            documents = loader.load_and_split()\n",
    "        elif '.docx' in doc.name:\n",
    "            loader = Docx2txtLoader(file_name)\n",
    "            documents = loader.load_and_split()\n",
    "        elif '.pptx' in doc.name:\n",
    "            loader = UnstructuredPowerPointLoader(file_name)\n",
    "            documents = loader.load_and_split()\n",
    "#여러개의 파일을 처리했기 떄문에 extend를 통해 doc_list에 담아 return함\n",
    "        doc_list.extend(documents)\n",
    "    return doc_list\n",
    "\n",
    "#\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=900,\n",
    "        chunk_overlap=100,\n",
    "        length_function=tiktoken_len\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(text)\n",
    "    return chunks\n",
    "\n",
    "#텍스트를 벡터화 시키는 과정임\n",
    "#스트림릿 클라우드에서 돌아가는 pc는 gpu가 없어서 cpu를 디바이스로 설정함\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "                                        model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "                                        model_kwargs={'device': 'cpu'},\n",
    "                                        encode_kwargs={'normalize_embeddings': True}\n",
    "                                        )  \n",
    "    vectordb = FAISS.from_documents(text_chunks, embeddings)\n",
    "    return vectordb\n",
    "#ㅇ원래 메모리라는 매게변수가 없엇는데 chat_history라는 키값을 가진 채팅기록을 찾아오고 이걸 컨텍스트에 집어 넣어 이전 대화를 기억하게함\n",
    "#output_key를 answer로 설정해서 대화를 나눈것 중에서 답변에 대항하는 부분만 history에 담겠다는것\n",
    "#get_chat_history=lambda h: h메모리가 들어온 그대로 chat_history에 넣ㄷ겠따\n",
    "#return_source_documents=True, llm이 참고한 문서 출력\n",
    "def get_conversation_chain(vetorestore,openai_api_key):\n",
    "    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name = 'gpt-3.5-turbo',temperature=0)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm, \n",
    "            chain_type=\"stuff\", \n",
    "            retriever=vetorestore.as_retriever(search_type = 'mmr', vervose = True), \n",
    "            memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),\n",
    "            get_chat_history=lambda h: h,\n",
    "            return_source_documents=True,\n",
    "            verbose = True\n",
    "        )\n",
    "\n",
    "    return conversation_chain\n",
    "\n",
    "\n",
    "# 함수실행하면 시작됨\n",
    "#만약 이 파일이 실행되면 poc로 만들 화면의 스크립트가 모두작성되는것임\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "#배포를 하기위해서는 다른것들이 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67ebc4",
   "metadata": {},
   "source": [
    "배포를 위해서 poc 스크립트가 있는 py파일과 requirements.txt파일이 필요함 \n",
    "\n",
    "이건 스크립트에서 정의한 라이브러리가 스트림릿 클라우드에서 작동하게 하는것임 \n",
    "\n",
    "그럼 스트림릿 클라우드가 pip install로 다운 받아서 구동되게함\n",
    "\n",
    "share.streamlit.io에 들어가면 새로운 앱을 개발할 수 있는 사이트가나옴 \n",
    "뉴앱을 선택 ㄲ\n",
    "깃허베 있는 레포지토리 선택 브랜치 선택 메인파일 경로 선택(poc스크립트파일) app url은 어떤 url을 사용할건지임\n",
    "\n",
    "advanced setting은 예를들어 사내에 poc를 구축할 떄 open api키를 모든 사용자가 가져올 수 없으니 poc구축자만 알고 사용자들이 정체를 모르겠끔\n",
    "\n",
    "사용자가 직접 api키를 입력하지 않아도 poc가 구동되는데 무리없음 \n",
    "이건 보안과 관련된 부분이라 유용함 직접해보고 모르면 유튜브참고 ㄱ ㄱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f8203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahdgks",
   "language": "python",
   "name": "ahdgks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
